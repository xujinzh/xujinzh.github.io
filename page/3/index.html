<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>J. Xu - 众妙之门</title><meta name="author" content="Jinzhong Xu"><meta name="copyright" content="Jinzhong Xu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="众妙之门">
<meta property="og:type" content="website">
<meta property="og:title" content="J. Xu">
<meta property="og:url" content="https://xujinzh.github.io/page/3/index.html">
<meta property="og:site_name" content="J. Xu">
<meta property="og:description" content="众妙之门">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://xujinzh.github.io/img/silence.jpg">
<meta property="article:author" content="Jinzhong Xu">
<meta property="article:tag" content="数学、计算机视觉、计算机应用技术">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xujinzh.github.io/img/silence.jpg"><link rel="shortcut icon" href="/img/letter-j.png"><link rel="canonical" href="https://xujinzh.github.io/page/3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'J. Xu',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-07-17 18:12:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/silence.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">403</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">312</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="J. Xu"><img class="site-icon" src="/img/letter-j.png"/><span class="site-name">J. Xu</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/13/ai-internlm-lmdeploy/" title="基于 LMDeploy 的大模型量化和部署"><img class="post-bg" src="/img/c26.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于 LMDeploy 的大模型量化和部署"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/13/ai-internlm-lmdeploy/" title="基于 LMDeploy 的大模型量化和部署">基于 LMDeploy 的大模型量化和部署</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-13T06:07:33.000Z" title="发表于 2024-01-13 14:07:33">2024-01-13</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.088Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/research/">research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/research/deep-learning/">deep learning</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ai/">ai</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/llm/">llm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/internlm/">internlm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/openmmlab/">openmmlab</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/langchain/">langchain</a></span></div><div class="content">本篇介绍如何在 Jupyter Notebook 中使用 LMDeploy 对大模型进行量化和部署。



环境配置Terminal 中执行下面命令：
12345conda create -n lmdeploy --clone /share/conda_envs/internlm-baseconda activate lmdeploypip install ipykernelpython -m ipykernel install --user --name lmdeploy --display-name lmdeploy

创建 notebook，选择内核 lmdeploy，执行一下代码
1234567891011# 设置notebook环境import os, sysPATH = os.environ[&#x27;PATH&#x27;]basedir = os.path.dirname(os.path.dirname(sys.exec_prefix))# 这里的 $PATH 也可以替换为 &#123;os.environ[&#x27;PATH&#x27;]&#125;。这里只是为了展 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/01/12/ai-internlm-personal-assistant-based-on-xtuner/" title="利用 XTuner 训练书生·浦语私人大模型助手"><img class="post-bg" src="/img/c8.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="利用 XTuner 训练书生·浦语私人大模型助手"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/12/ai-internlm-personal-assistant-based-on-xtuner/" title="利用 XTuner 训练书生·浦语私人大模型助手">利用 XTuner 训练书生·浦语私人大模型助手</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-12T11:03:54.000Z" title="发表于 2024-01-12 19:03:54">2024-01-12</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.088Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/research/">research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/research/deep-learning/">deep learning</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ai/">ai</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/llm/">llm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/internlm/">internlm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/openmmlab/">openmmlab</a></span></div><div class="content">本篇介绍如何使用 XTuner 微调 InternLM 称为私人智能助手。



目标：使用 XTuner 微调 InternLM-Chat 模型，使得其能够知道它的主人是谁。
环境配置先在命令行终端执行下面命令：

conda create –name personal_assistant python&#x3D;3.10 -y
conda activate personal_assistant
pip install ipykernel
python -m ipykernel install –user –name personal_assistant –display-name personal_assistant

1234567891011# 设置notebook环境import os, sysPATH = os.environ[&#x27;PATH&#x27;]basedir = os.path.dirname(os.path.dirname(sys.exec_prefix))# 这里的 $PATH 也可以替换为 &#123;os.environ[&#x27;PATH&#x ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/12/ai-internlm-xtuner-finetune/" title="XTuner 大模型训练"><img class="post-bg" src="/img/c2.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="XTuner 大模型训练"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/12/ai-internlm-xtuner-finetune/" title="XTuner 大模型训练">XTuner 大模型训练</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-12T10:03:54.000Z" title="发表于 2024-01-12 18:03:54">2024-01-12</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.088Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/research/">research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/research/deep-learning/">deep learning</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ai/">ai</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/llm/">llm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/internlm/">internlm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/openmmlab/">openmmlab</a></span></div><div class="content">本篇介绍如何使用 XTuner 进行大模型训练与微调。



环境配置12345# 在终端执行这些命令conda create --name xtuner0.1.9 python=3.10 -yconda activate xtuner0.1.0pip install ipykernelpython -m ipykernel install --user --name xtuner --display-name xtuner

刷新 notebook， 选择新内核 xtuner
12%cd ~%mkdir xtuner019 &amp;&amp; cd xtuner019


1!git clone -b v0.1.9 https://github.com/InternLM/xtuner


1%cd xtuner


1%pip install -e &#x27;.[all]&#x27;


12%mkdir ~/ft-oasst1%cd ~/ft-oasst1


1import os, sys


12PATH = os.environ[&#x27;PATH&#x27;]PATH ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/01/08/ai-Interlm-langchain-RAG/" title="基于 InternLM 和 LangChain 搭建私人知识库"><img class="post-bg" src="/img/c30.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于 InternLM 和 LangChain 搭建私人知识库"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/08/ai-Interlm-langchain-RAG/" title="基于 InternLM 和 LangChain 搭建私人知识库">基于 InternLM 和 LangChain 搭建私人知识库</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-08T15:33:33.000Z" title="发表于 2024-01-08 23:33:33">2024-01-08</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.088Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/research/">research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/research/deep-learning/">deep learning</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ai/">ai</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/llm/">llm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/internlm/">internlm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/openmmlab/">openmmlab</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/langchain/">langchain</a></span></div><div class="content">本篇介绍基于 InternLM 和 LangChain 搭建私人知识库。


环境配置12345!conda create --name internlm_langchain --clone=/root/share/conda_envs/internlm-base!/root/.conda/envs/internlm_langchain/bin/python -m pip install ipykernel ipywidgets!/root/.conda/envs/internlm_langchain/bin/python -m ipykernel install --user --name internlm_langchain --display-name internlm_langchain# refresh web and use new kernel internlm_langchain


1234# 升级pip%pip install -q --upgrade pip%pip install -q modelscope==1.9.5 transformers==4.35.2 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/06/ai-internlm-useage/" title="书生·浦语大模型使用"><img class="post-bg" src="/img/c11.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="书生·浦语大模型使用"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/06/ai-internlm-useage/" title="书生·浦语大模型使用">书生·浦语大模型使用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-06T08:44:54.000Z" title="发表于 2024-01-06 16:44:54">2024-01-06</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.088Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/research/">research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/research/deep-learning/">deep learning</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ai/">ai</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/llm/">llm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/internlm/">internlm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/openmmlab/">openmmlab</a></span></div><div class="content">本篇介绍书生·浦语大模型的使用，包括智能对话、智能体工具调用和图文理解创作等。


InternLM-Chat-7B 智能对话环境配置12345!conda create --name internlm-chat --clone=/root/share/conda_envs/internlm-base!/root/.conda/envs/internlm-chat/bin/python -m pip install ipykernel ipywidgets!/root/.conda/envs/internlm-chat/bin/python -m ipykernel install --user --name internlm-chat --display-name internlm-chat# restart kernel and use internlm-chat env


12%pip install -q --upgrade pip%pip install -q modelscope==1.9.5 transformers==4.35.2 streamlit==1.24.0  ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/01/05/ubuntu-18-04-install-glibc2-28/" title="Ubuntu 18.04 上安装 glibc 2.28 支持 QT6"><img class="post-bg" src="/img/c25.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Ubuntu 18.04 上安装 glibc 2.28 支持 QT6"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/05/ubuntu-18-04-install-glibc2-28/" title="Ubuntu 18.04 上安装 glibc 2.28 支持 QT6">Ubuntu 18.04 上安装 glibc 2.28 支持 QT6</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-05T01:39:33.000Z" title="发表于 2024-01-05 09:39:33">2024-01-05</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-26T06:04:35.857Z" title="更新于 2024-04-26 14:04:35">2024-04-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/technology/">technology</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/technology/ubuntu/">ubuntu</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ubuntu/">ubuntu</a></span></div><div class="content">最新的 QT6 需要 GLIBC_2.28 的支持，但是 Ubuntu18.04 上最高的 GLIBC 版本是 2.27，无法满足。本篇介绍如何在 Ubuntu18.04 上安装 GLIBC_2.28.


查看系统支持的 GLIBC 版本号1234ldd --version# orstrings /lib/x86_64-linux-gnu/libc.so.6 | grep GLIBC_

安装 GLIBC 2.281234567sudo su -c &#x27;echo &quot;deb http://security.debian.org/debian-security buster/updates main&quot; &gt;&gt; /etc/apt/sources.list&#x27; rootsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A 54404762BBB6E853sudo apt updatesudo apt install libc6 libc6-de ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/01/03/ai-internlm-intro/" title="书生·浦语大模型介绍"><img class="post-bg" src="/img/c6.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="书生·浦语大模型介绍"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/01/03/ai-internlm-intro/" title="书生·浦语大模型介绍">书生·浦语大模型介绍</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-03T14:33:54.000Z" title="发表于 2024-01-03 22:33:54">2024-01-03</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.088Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/research/">research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/research/deep-learning/">deep learning</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ai/">ai</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/llm/">llm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/internlm/">internlm</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/openmmlab/">openmmlab</a></span></div><div class="content">本篇简单介绍上海人工智能实验室的书生·浦语大模型。

书生·浦语大模型包含三大类：

轻量级：InternLM-7B，社区低成本可用最佳模型规模
中量级：InternLM-20B，商业场景可开发定制高精度较小模型规模
重量级：InternLM-123B，通用大语言模型能力全面覆盖千亿模型规模

数据 书生·万卷书生·万卷多达 2TB 数据，涵盖多种模态和任务。发布日期 2023 年 8 月 14 日。包含文本数据（50 亿个文档，数据量超 1TB），图像-文本数据集（超 2200 万个文件，数据量超 140GB），视频数据（超 1000 个文件，数据量超 900GB）。
OpenDataLab 提供了更多的开放数据。
预训练 InternLM-Train并行训练，极致优化。速度达到 3600 tokens&#x2F;sec&#x2F;gpu。
支持从 8 卡到千卡训练，千卡训练效率达 92%；无缝接入 HuggingFace 等技术生态，支持各类轻量化技术。
微调 XTunerXTuner 是一种高效的大模型微调框架：

支持多种任务类型，如增量预训练，指令微调，工具类指令微调
支持全 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/11/24/python-look-model-structure-by-timm/" title="使用 timm 模块查看常见深度学习模型结构"><img class="post-bg" src="/img/c16.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用 timm 模块查看常见深度学习模型结构"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/11/24/python-look-model-structure-by-timm/" title="使用 timm 模块查看常见深度学习模型结构">使用 timm 模块查看常见深度学习模型结构</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-11-24T09:24:14.000Z" title="发表于 2023-11-24 17:24:14">2023-11-24</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.104Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/technology/">technology</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/technology/python/">python</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/dl/">dl</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/python/">python</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/timm/">timm</a></span></div><div class="content">深度学习中预训练模型库非常重要，它能够帮助我们非常方便的获取到模型的结构、模型的权重文件等，这大大降低了入门深度学习的门槛，如高性能的硬件设备（服务器、GPU），同时使用迁移学习的思想能够大大缩短我们开发可实用模型的时间。常见的预训练模型库包含有 torchvision.models(CV 模型)、transformers(CV 和 NLP 大模型相关)、timm(包含 CV 领域小模型和大模型，开发公司同 transformers 的 hugging face)。其中 timm 非常方便我们查看模型结构，同时可加载预训练的模型权重，且支持的模型比较多。本篇介绍 timm。



安装timm 的官方网址是：https://github.com/huggingface/pytorch-image-models
1pip install timm


使用查看预训练模型1234import timmavail_pretrained_models = timm.list_models(pretrained=True)len(avail_pretrained_models)
12# 截止目前 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/10/18/jupyter-install-package/" title="在 jupyter 中安装 Python 第三方软件包"><img class="post-bg" src="/img/c17.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="在 jupyter 中安装 Python 第三方软件包"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/10/18/jupyter-install-package/" title="在 jupyter 中安装 Python 第三方软件包">在 jupyter 中安装 Python 第三方软件包</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-18T06:19:32.000Z" title="发表于 2023-10-18 14:19:32">2023-10-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.096Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/technology/">technology</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/technology/python/">python</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/python/">python</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/pip/">pip</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/jupyter/">jupyter</a></span></div><div class="content">经常使用 Jupyter 的用户常常着迷于其友好的历史命令记录功能，这样能够非常方便的查看和分享我们在编写和运行代码时都是使用了什么命令，能够很好的用于回顾、排查和分享程序等，如执行该项目安装的软件以及方法等。本篇介绍如何在 jupyter 中安装 Python 第三方软件。



借助 IPython 魔法命令IPython 是一种基于 Python 交互式解释器，提供了更为强大的编辑和交互功能。在 IPython 中最为重要的就是其提供的魔法命令，Jupyter 使用 IPython 作为其 Python 内核，同样能够使用 IPython 的魔法命令。在 IPython 中有两个 line 魔法命令（以一个 % 开头）：%pip 和 %conda。
1234567891011121314# 安装到当前 jupyter notebook 使用的运行环境%pip install rich streamlit# 通过源码安装最新版%pip install git+https://github.com/huggingface/transformers.git@main# 通过源码安装指定 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/10/16/python-huggingface-model-usage/" title="huggingface 模型的使用"><img class="post-bg" src="/img/c25.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="huggingface 模型的使用"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/10/16/python-huggingface-model-usage/" title="huggingface 模型的使用">huggingface 模型的使用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-16T07:31:15.000Z" title="发表于 2023-10-16 15:31:15">2023-10-16</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.100Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/technology/">technology</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/technology/python/">python</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/python/">python</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/huggingface/">huggingface</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/model/">model</a></span></div><div class="content">Hugging Face 是一家于 2016 年成立的美国公司，专门开发用于构建机器学习应用的工具。该公司的代表产品是其为自然语言处理应用构建的transformers库，以及允许用户共享机器学习模型和数据集的平台。本篇介绍如何使用 Python 使用 Hugging Face 上的模型。


配置环境使用 Hugging Face 的模型库，必然需要使用其公司开发的 transformers 模型库软件包。Transformers模型库（Transformers Library）是一个Python软件包，其中包含了用于文本、图像和音频任务的Transformer模型的开源实现。它与PyTorch、TensorFlow和JAX深度学习库兼容，并包括了BERT和GPT-2等知名模型的实现。该库最初名为“pytorch-pretrained-bert”，后来更名为“pytorch-transformers”，最终改名为“transformers”。
本篇以 Salesforce&#x2F;blip2-flan-t5-xl 为例演示。更多模型库请访问 Hugging Face 官网 查看 M ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/10/12/git-tag/" title="git 给仓库打标签 tag"><img class="post-bg" src="/img/c10.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="git 给仓库打标签 tag"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/10/12/git-tag/" title="git 给仓库打标签 tag">git 给仓库打标签 tag</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-12T02:55:32.000Z" title="发表于 2023-10-12 10:55:32">2023-10-12</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-30T15:35:56.096Z" title="更新于 2024-01-30 23:35:56">2024-01-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/technology/">technology</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/technology/linux/">linux</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/git/">git</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/tag/">tag</a></span></div><div class="content">在使用 git 进行代码版本控制的时候，常常会使用打标签以示重要版本。如 open-mmlab&#x2F;mmdetection 仓库中和分支（Branches）并列的 Tags 列，标识了不同 mmdetection 的重要版本更新，如 v1.0.0, v2.0.0, v3.0.0，目前最新版的是 v3.1.0。本篇介绍如何给自己的仓库打标签。



创建标签为当前版本库创建标签有两种方法，一种是附注标签，一种是轻量标签。有时，我们想为历史版本创建标签，称为后期标签。
轻量标签很像一个不会改变的分支——它只是某个特定提交的引用。
而附注标签是存储在 Git 数据库中的一个完整对象， 它们是可以被校验的，其中包含打标签者的名字、电子邮件地址、日期时间， 此外还有一个标签信息，并且可以使用 GNU Privacy Guard （GPG）签名并验证。 通常会建议创建附注标签，这样你可以拥有以上所有信息。但是如果你只是想用一个临时的标签， 或者因为某些原因不想要保存这些信息，那么也可以用轻量标签。
附注标签12345678# 给当前版本库打上标签 v1.0，并附上说明文字git tag -a ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#content-inner">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/37/#content-inner">37</a><a class="extend next" rel="next" href="/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/silence.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Jinzhong Xu</div><div class="author-info__description">众妙之门</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">403</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">312</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xujinzh"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xujinzh" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:xujinzhong027@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://www.mathscv.com" target="_blank" title="MathsCVBlog"><i class="fab fa-j"></i></a><a class="social-icon" href="https://xujinzh.github.io" target="_blank" title="GitHubBlog"><i class="fab fa-github-alt"></i></a><a class="social-icon" href="https://www.mathscv.com/power" target="_blank" title="MathsCVPower"><i class="fab fa-m"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">日本核污染水强排入海！</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/07/16/linux-limit-tcp-speed-by-trickle/" title="使用 trickle 限制 linux 上应用程序的下载和上传速度"><img src="/img/c17.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用 trickle 限制 linux 上应用程序的下载和上传速度"/></a><div class="content"><a class="title" href="/2024/07/16/linux-limit-tcp-speed-by-trickle/" title="使用 trickle 限制 linux 上应用程序的下载和上传速度">使用 trickle 限制 linux 上应用程序的下载和上传速度</a><time datetime="2024-07-16T02:01:08.000Z" title="发表于 2024-07-16 10:01:08">2024-07-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/09/ai-pytorch-model-infer-acc-onnx-tensorrt/" title="使用 tensorrt 加速 pytorch 模型推理"><img src="/img/c3.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用 tensorrt 加速 pytorch 模型推理"/></a><div class="content"><a class="title" href="/2024/07/09/ai-pytorch-model-infer-acc-onnx-tensorrt/" title="使用 tensorrt 加速 pytorch 模型推理">使用 tensorrt 加速 pytorch 模型推理</a><time datetime="2024-07-09T11:25:01.000Z" title="发表于 2024-07-09 19:25:01">2024-07-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/09/linux-vlc-root/" title="Ubuntu 上安装 vlc 并使用 root 用户播放"><img src="/img/c11.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Ubuntu 上安装 vlc 并使用 root 用户播放"/></a><div class="content"><a class="title" href="/2024/07/09/linux-vlc-root/" title="Ubuntu 上安装 vlc 并使用 root 用户播放">Ubuntu 上安装 vlc 并使用 root 用户播放</a><time datetime="2024-07-09T01:05:21.000Z" title="发表于 2024-07-09 09:05:21">2024-07-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/02/ai-llm-deploy-simple/" title="本地大模型部署方案之一：ollama 和 open webui"><img src="/img/c29.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="本地大模型部署方案之一：ollama 和 open webui"/></a><div class="content"><a class="title" href="/2024/07/02/ai-llm-deploy-simple/" title="本地大模型部署方案之一：ollama 和 open webui">本地大模型部署方案之一：ollama 和 open webui</a><time datetime="2024-07-02T11:10:49.000Z" title="发表于 2024-07-02 19:10:49">2024-07-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/19/nvidia-smi-memory-release/" title="NVIDIA GPU 显存释放"><img src="/img/c16.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="NVIDIA GPU 显存释放"/></a><div class="content"><a class="title" href="/2024/04/19/nvidia-smi-memory-release/" title="NVIDIA GPU 显存释放">NVIDIA GPU 显存释放</a><time datetime="2024-04-19T10:11:54.000Z" title="发表于 2024-04-19 18:11:54">2024-04-19</time></div></div></div></div><div class="card-widget" id="card-newest-comments"><div class="item-headline"><i class="fas fa-comment-dots"></i><span>最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/maths/"><span class="card-category-list-name">maths</span><span class="card-category-list-count">34</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/maths/algebra/"><span class="card-category-list-name">algebra</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/maths/application/"><span class="card-category-list-name">application</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/maths/mathematical-analysis/"><span class="card-category-list-name">mathematical analysis</span><span class="card-category-list-count">22</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/maths/mathematician/"><span class="card-category-list-name">mathematician</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/maths/optimization/"><span class="card-category-list-name">optimization</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/maths/probability/"><span class="card-category-list-name">probability</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/maths/topology/"><span class="card-category-list-name">topology</span><span class="card-category-list-count">1</span></a></li></ul></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/pandoc/" style="font-size: 1.1em; color: #999">pandoc</a> <a href="/tags/hexo/" style="font-size: 1.34em; color: #99a3b0">hexo</a> <a href="/tags/visdom/" style="font-size: 1.1em; color: #999">visdom</a> <a href="/tags/hostname/" style="font-size: 1.18em; color: #999ca1">hostname</a> <a href="/tags/rsync/" style="font-size: 1.1em; color: #999">rsync</a> <a href="/tags/chrome/" style="font-size: 1.18em; color: #999ca1">chrome</a> <a href="/tags/jaccard/" style="font-size: 1.1em; color: #999">jaccard</a> <a href="/tags/convex/" style="font-size: 1.1em; color: #999">convex</a> <a href="/tags/ot/" style="font-size: 1.1em; color: #999">ot</a> <a href="/tags/tag/" style="font-size: 1.1em; color: #999">tag</a> <a href="/tags/notebook/" style="font-size: 1.1em; color: #999">notebook</a> <a href="/tags/snap/" style="font-size: 1.1em; color: #999">snap</a> <a href="/tags/vim/" style="font-size: 1.18em; color: #999ca1">vim</a> <a href="/tags/otb/" style="font-size: 1.1em; color: #999">otb</a> <a href="/tags/ls/" style="font-size: 1.1em; color: #999">ls</a> <a href="/tags/ubuntu/" style="font-size: 1.5em; color: #99a9bf">ubuntu</a> <a href="/tags/putty/" style="font-size: 1.1em; color: #999">putty</a> <a href="/tags/integral/" style="font-size: 1.34em; color: #99a3b0">integral</a> <a href="/tags/completeness/" style="font-size: 1.1em; color: #999">completeness</a> <a href="/tags/aria2/" style="font-size: 1.18em; color: #999ca1">aria2</a> <a href="/tags/htop/" style="font-size: 1.1em; color: #999">htop</a> <a href="/tags/jupyterhub/" style="font-size: 1.18em; color: #999ca1">jupyterhub</a> <a href="/tags/host-only/" style="font-size: 1.1em; color: #999">host-only</a> <a href="/tags/windows10/" style="font-size: 1.18em; color: #999ca1">windows10</a> <a href="/tags/whl/" style="font-size: 1.1em; color: #999">whl</a> <a href="/tags/random/" style="font-size: 1.1em; color: #999">random</a> <a href="/tags/AriaNg/" style="font-size: 1.1em; color: #999">AriaNg</a> <a href="/tags/latex/" style="font-size: 1.26em; color: #999fa8">latex</a> <a href="/tags/windows/" style="font-size: 1.42em; color: #99a6b7">windows</a> <a href="/tags/code-server/" style="font-size: 1.1em; color: #999">code-server</a> <a href="/tags/tmux/" style="font-size: 1.1em; color: #999">tmux</a> <a href="/tags/tcp/" style="font-size: 1.1em; color: #999">tcp</a> <a href="/tags/sshfs/" style="font-size: 1.1em; color: #999">sshfs</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/02/"><span class="card-archive-list-date">二月 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">一月 2024</span><span class="card-archive-list-count">11</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">十一月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">十月 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">九月 2023</span><span class="card-archive-list-count">4</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">403</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2019-07-16T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">468.7k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-07-17T10:12:10.625Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Jinzhong Xu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const findTrueUrl = (array) => {
    Promise.all(array.map(item =>
      fetch(item.url).then(resp => resp.json()).then(data => {
        const urlArray = data.body.match(/(https?:\/\/)?([\da-z\.-]+)\.([a-z\.]{2,6})([\/\w \.-]*)*\/?/ig)
        if (data.user.login === 'utterances-bot') {
          return urlArray.pop()
        } else {
          return urlArray.shift()
        }
      })
    )).then(res => {
        array = array.map((i,index)=> {
          return {
            ...i,
            url: res[index]
          }
        })

        saveToLocal.set('github-newest-comments', JSON.stringify(array), 10/(60*24))
        generateHtml(array)
    });
  }

  const getComment = () => {
    fetch('https://api.github.com/repos/xujinzh/xujinzh.github.io/issues/comments?sort=updated&direction=desc&per_page=6&page=1',{
      "headers": {
        Accept: 'application/vnd.github.v3.html+json'
      }
    })
      .then(response => response.json())
      .then(data => {
        const githubArray = data.map(item => {
          return {
            'avatar': item.user.avatar_url,
            'content': changeContent(item.body_html),
            'nick': item.user.login,
            'url': item.issue_url,
            'date': item.updated_at,
            'githubUrl': item.html_url
          }
        })
        findTrueUrl(githubArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('github-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="true" data-text="众,妙,之,门" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></body></html>